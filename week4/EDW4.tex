\documentclass[10pt]{beamer}

\input{../utils/beamerpreamble.tex}

% TODO: this class needs more real examples from real data.


\title[]{Experiment Planning and Design}
\subtitle[]{Lecture 4: Statistical Concepts}
\author[Claus Aranha]{Claus Aranha\\{\footnotesize caranha@cs.tsukuba.ac.jp}}
\institute{Department of Computer Science}
\date{2015-05-12}

\begin{document}

\section{Outline}
\subsection{Outline}

\begin{frame}
  \maketitle
\end{frame}

\begin{frame}
  \frametitle{Notes} 
  \begin{itemize}
  \item Sorry about the sickness last class; Let's try Class 3 again!

    \bigskip

  \item No class on May 19th and May 26th;
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Class Outline}
  \begin{itemize}
  \item Random Variables
  \item Point Estimators
  \item Interval Estimators
  \item Hypothesis Testing
  \end{itemize}
  \begin{exampleblock}{}
    The goal of this class is to allow you to do a simple analysis of
    the data going into, and coming out of an experiment.
  \end{exampleblock}
\end{frame}

\section{Introduction}
\subsection{Introduction}
\begin{frame}
  \frametitle{Introduction: Probability vs Statistics}
  \begin{columns}
    \column{0.5\textwidth}
    \begin{block}{Probability}
      Given the pool, what are the odds of drawing a combination of certain colors?
      \begin{center}
      \includegraphics[height=.35\textheight]{img/ballpool}
      \end{center}
    \end{block}
    \column{0.5\textwidth}
    \begin{block}{Statistics}
      Given the colors of a few balls drawn, what can I know about the pool?
      \begin{center}
      \includegraphics[height=.35\textheight]{img/ballhand}
      \end{center}
    \end{block}
  \end{columns}

  \bigskip

  \structure{Statistical Inference:} Using \emph{samples} to draw
  conclusions about \emph{populations}
\end{frame}

\begin{frame}
  \frametitle{Population, Sample and Observation}
  \begin{columns}
    \column{0.9\textwidth} ``A \structure{population} is a large set
    of objects of a similar nature which is of interest as a
    whole''. It can be an actual set (all balls in the pool), or an
    hypothetical one (all possible outcomes for an experiment).
    \column{0.1\textwidth}
    \includegraphics[width=1\textwidth]{img/ballpool}
  \end{columns}
  \vspace{.6cm}
  \begin{columns}
    \column{0.1\textwidth}
    \includegraphics[width=1\textwidth]{img/ballhand}
    \column{0.9\textwidth} A \structure{sample} is a subset of a
    population. ``A sample is chosen to make inferences about the
    population by examining or measuring the elements in the sample''
  \end{columns}
  \vspace{.6cm}
  \begin{columns}
    \column{0.9\textwidth} An \structure{observation} is a single
      element of a given sample, an individual data point. An
      observation can also be considered as a sample of size one.
      \column{0.1\textwidth}
      \includegraphics[width=1\textwidth]{img/greenball}
  \end{columns}

  \vspace{2cm}

  \rule{\textwidth}{0.4pt}
  \smaller{Glossary of statistical terms: \url{http://www.statistics.com/glossary}}
\end{frame}

\begin{frame}
  \frametitle{Population, Sample and Observation} 

  \begin{exampleblock}{Let's remember Alice and Bob's experiments}
    Alice and Bob build spam filter programs. They test their programs
    by counting how many spam the system catches in a day.
  \end{exampleblock}


  \begin{block}{Observation}
    \only<2>{
    If we count the number of spam caught by a system in one day, that
    is \structure{one observation}.

    \medskip
    
    If we count the number of spam caught by a system another day,
    that is \structure{a second observation}}
  \end{block}

  \begin{block}{Sample}
    
    \only<3>{If we count the number os spam caught every day for a
      week, we will have seven observations. That is a
      \structure{Sample}}
  \end{block}
  
  \begin{block}{Population}
    \only<4>{
      If we know ALL possible results for ALL possible days, that is the \structure{Population}
      
      \medskip
      
      In practice, it is \alert{usually impossible to KNOW} the
      population, but we want to learn \alert{as much as possible}
      from it, by observing samples.
    }
  \end{block}


\end{frame}

\section{Point and Interval Estimates}
\subsection{Concepts}

\begin{frame}
  \frametitle{Point and Interval Estimates} 

  Two central concepts of \structure{Statistical Inference} are
  \structure{point estimators} and \structure{statistical intervals}

  \medskip

  Both terms refer to the idea of using information obtained from a
  \structure{sample} to infer values about parameters of the
  \structure{population}.

  \vfill

  \begin{itemize}
    \item \structure{Point Estimate}: Estimate a value for a given population parameter
    \item \structure{Statistical Interval}: Estimate a interval of
      possible/probable values for a given population parameter;
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Point Estimates, Statistics, and Sampling distributions}
  
  Suppose one wants to obtain a point estimate for the mean of a given
  population. We take a sample of the population, and calculate the
  mean of that sample.

  \medskip

  However, a random sample from a population results in a random
  variable! Any function of the sample - any \emph{statistic} - is
  also a random variable.

  \medskip

  This means that statistics calculated from samples will also have
  their own probability distributions, called \structure{sampling
    distributions}.
  
  \begin{center}
    \includegraphics[width=0.3\textwidth]{img/meanestimator}
  \end{center}
  
  \rule{\textwidth}{0.4pt}
  {\tiny See D.W. Stockburger: \url{http://www.psychstat.missouristate.edu/introbook/sbk19.htm}}
\end{frame}

\begin{frame}[singleframe,fragile]
  \frametitle{I heard you like statistics!}
  {\small
  \begin{block}{}
    \begin{columns}
      
      \column{0.7\textwidth} 
      So in order to specify parameters of the population (such as
      means, deviation, etc), we draw a random sample and calculate the
      parameters from it.  
      \medskip

      But because the sample is random, the parameter calculated from
      the sample will also have its own statistics!
      \column{0.2\textwidth}
      \includegraphics[width=.8\textwidth]{img/yodawg}      
    \end{columns}
  \end{block}
  \begin{exampleblock}{Everything is easier with an R example}
\begin{verbatim}
> population <- rnorm(100) # Pretend you don't know this!
> x1 <- sample(population,5)
> x2 <- sample(population,5)
> x3 <- sample(population,5)
> x1
[1]  0.6028260  0.1333065  1.1145946 -0.8675467 -0.4329469
> c(pop=mean(population),x1=mean(x1),x2=mean(x2),x3=mean(x3))
        pop          x1          x2          x3 
 0.05722922  0.11004669 -0.10459150  0.12630965
> c(mean(c(mean(x1),mean(x2),mean(x3))),sd(c(mean(x1),mean(x2),mean(x3))))
[1] 0.04392161 0.12887292
\end{verbatim}
  \end{exampleblock}
}
\end{frame}

\subsection{Point Estimators}
\begin{frame}
  \frametitle{Point Estimators}

  A \structure{Point Estimator} is a statistic which provides the
  value of maximum plausibility for a given (unknown) population
  parameter $\theta$.

  \medskip

  Consider a random variable $X$ distributed according to a given
  $f(X|\theta)$ (a population which distribution is controlled by this
  parameter)

  \medskip

  Now consider also a random sample from this variable:\\
  $x = \{x_1,x_2,\dots,x_N\}$;

  \medskip

  A given function $\hat{\Theta} = h(x)$ is called a \emph{point
    estimator} of the parameter $\theta$, and a value returned by this
  function for a given sample is referred to as a \emph{point estimate
    $\hat{\theta}$} of the parameter.
  
  \medskip

  \begin{block}{What does this mean?}
    A \structure{Point Estimator} is a function that, given a sample,
    generates an estimated parameter for the distribution from which
    the sample was obtained. 
  \end{block}

\end{frame}

\begin{frame}
  \frametitle{Point Estimators} 

  Point estimation problems arise frequently in all areas of science
  and engineering, whenever there is a need for estimating a parameter
  of a population:
  \begin{itemize}
    \item The population mean, $\mu$;
    \item The population variange, $\sigma^2$;
    \item a population proportion, $p$;
    \item the difference in the means of two populations, $\mu_1 - \mu_2$;
    \item etc...
  \end{itemize}

  For each cases (and many others) there are multiple ways of
  performing the estimation task. We choose the estimators based on
  its statistics.
  
  {\smaller
  \begin{exampleblock}{Multiple estimators?}
    We always consider only one definition for estimators (e.g., the
    mean). But we can be creative and invent others!

    \begin{equation*}
      \mu = \sum^N_{i=0}\frac{x_i}{N}
    \end{equation*}
    \begin{equation*}
      \mu' = \frac{max(x) - min(x)}{2}
    \end{equation*}
  \end{exampleblock}}
\end{frame}

\begin{frame}
  \frametitle{Evaluating Estimators} 

  A good estimator should consistently generate estimates that are
  close to the real value of the parameter $\theta$.

  \bigskip

  We say that an estimator $\hat{Theta}$ is \structure{unbiased} for a parameter $\theta$ if:
  \begin{equation*}
    E[\hat{\Theta}] = \theta
  \end{equation*}
  or, equivalently:
  \begin{equation*}
    E[\hat{\Theta}] - \theta = 0.
  \end{equation*}

  \bigskip

  The difference $E[\hat{\Theta}] - \theta$ is referred as the
  \structure{bias} of an estimator.

\end{frame}

\begin{frame}
  \frametitle{Evaluating Estimators}
  The usual estimators for mean and variance are unbiased estimators;

  Let $x_1,\dots,x_N$ be a random sample from a given population $X$,
  which is characterized by its mean $\mu$ and variance $\sigma^2$. In
  this situation, it is possible to show that:
  \begin{equation*}
    E[\bar{x}] = E[\frac{1}{N}\sum_{i = 1}^Nx_i] = \mu
  \end{equation*}
  and:
  \begin{equation*}
    E[s^2] = E[\frac{1}{N-1}\sum^N_{i=1}(x_i-\bar{x})^2] = \sigma^2
  \end{equation*}

  \vspace{2cm}

  \rule{\textwidth}{0.4pt}
  {\tiny See this link for an example proof:
    \url{http://isites.harvard.edu/fs/docs/icb.topic515975.files/Proof\%20that\%20Sample\%20Variance\%20is\%20Unbiased.pdf}}
\end{frame}

\begin{frame}
  \frametitle{Evaluating Estimators (2)} 

  There usually exists more than one unbiased estimator for a
  parameter $\theta$. One way to choose which to use is to select the
  one with the smallest variance. This is generally called the
  \emph{minimal-variance unbiased estimator} (MVUE).
  \begin{center}
    \includegraphics[width=.6\textwidth]{img/ubes-var}
  \end{center}
  MVUE have the ability of generating estimates $\hat{\theta}$ that
  are relatively close to the real value.
\end{frame}

% TODO: Think about adding slides 12-14 from campelo class 3 (or replace by an example?)

\subsection{The Central Limit Theorem}
\begin{frame}
  \frametitle{Distribution of samples} 

  Even for an arbitrary population, the sampling distribution of means
  tends to be approximately normal (with $E[\bar{x}] = \mu$ and $s_{\bar{x}} = \sigma^2/N$

  \vfill

  \begin{alertblock}{Warning! Maths!}
    More generally, let $x_1,\dots,x_n$ be a sequence of independent
    and identically distributed (\structure{iid}) random variables,
    with mean $\mu$ and finite variance $\sigma^2$. Then:
    \begin{equation*}
      z_n = \frac{\sum^n_{i=1}(x_i)-n\mu}{\sqrt{n\sigma^2}}
    \end{equation*}
    is distributed approximately as a standard normal variable. That is, $z_n ~ N(0,1)$
    
    \medskip
    
    This is the \structure{Central Limit Theorem}.
  \end{alertblock}
\end{frame}

\begin{frame}[singleslide,fragile]
  \frametitle{Example of the Central Limit Theorem}
  
  \includegraphics[width=.45\textwidth]{img/CLT1}\hfill
  \includegraphics[width=.45\textwidth]{img/CLT5}

{\smaller
\begin{verbatim}
# Load the Teaching Demos library if you don't have it.
> install.packages("TeachingDemos")
> library(TeachingDemos)

> clt.examp()
> clt.examp(5)
\end{verbatim}}
\end{frame}

\begin{frame}
  \frametitle{Implications of the Central Limit Theorem} 

  The CLT is one of the most useful properties for statistical
  inference. The CLT allows the use of techniques based on the
  Gaussian distribution, even when the population under study is not
  normal.

  \bigskip
  
  For ``well-behaved'' distributions (continuous, symmetrical,
  unimodal) even small sample sizes are enough to justify invoking the
  CLT and using parametric techniques. 

  \bigskip

  For an interactive demonstration of the CLT, check:
  \url{http://drwho.cpdee.ufmg.br:3838/CLT/}
\end{frame}

% TODO: Add a numerical example of point estimators using R and some data

\begin{frame}
  \begin{center}
    mini-break, questions?
  \end{center}
\end{frame}


\section{Interval Estimators}
\subsection{Introduction}
\begin{frame}
  \frametitle{Statistical Intervals} 

  Statistical Intervals are important in quantifying the uncertainty
  associated to a given estimate;

  \bigskip
  
  % TODO: use a more relevant example to the students
  \begin{exampleblock}{Example: Coaxial cable factory}
    A coaxial cable manufacturing operation produces cables with a
    target resistance of 50$\Omega$ and a standard deviation of
    2$\Omega$. Assume that the resistance values of the cables
    produced can be well modeled by a normal distribution.
  \end{exampleblock}
  \begin{exampleblock}{}
    Suppose that we take a sample of $N = 25$ cables produced, and the
    sample mean is $\bar{x} = 48$. Given the variability of the
    sample, it is likely that this value is not exactly the true value
    $\mu$. 

    \medskip

    \structure{How can we quantify the uncertainty of this estimate?}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Definition of Statistical Intervals}
  \structure{Statistical Intervals} define regions that are likely to
  contain the true value of an estimated parameter.
 
  \medskip
  
  More formally, it is generally possible to quantify the level of
  uncertainty associated with the estimation, which allows the
  derivation of sound \structure{conclusions at predefined levels of
    certainty}.

  \begin{exampleblock}{Example}
    We estimate that the value of the mean of this population is
    between 5.3 and 7.8, and we have a 95\% confidence on the method
    used to generate this interval.
  \end{exampleblock}

  The most common types of interval are:
  \begin{enumerate}
  \item Confidence Intervals;
  \item Tolerance Intervals;
  \item Prediction Intervals;
  \end{enumerate}
\end{frame}

\subsection{Interval definitions}
\begin{frame}
  \frametitle{Confidence Intervals} 

  Confidence Intervals quantify the degree of uncertainty associated
  with the estimation of the population parameter, such as the mean or
  the variance.

  \begin{block}{Definition}
    ``The interval that contains the true value of a given population
    with a confidence level of $100(1-\alpha)$''
  \end{block}
  
  \bigskip
  
  \begin{itemize}
    \item \alert{Wrong:} ``there is a 95\% chance that the interval
      contains the true population mean'':
    \item \structure{Right:} ``The method used to derive the interval
      has a hit rate of 95\%'' - i.e., the interval generated has a
      95\% chance of capturing the true population parameter;
  \end{itemize}

  \medskip

  It is easier to understand if you think about confidence in the {\bf
    method}, not in the interval.
\end{frame}

\begin{frame}[singleslide,fragile]
  \frametitle{Example, 100 $CI_{.95}$ for a sample of 25 observations}
  \begin{center}
    \includegraphics[width=.9\textwidth]{img/CIs}
  \end{center}
  \medskip
\begin{verbatim}
> library(TeachingDemos)
> run.ci.examp()
\end{verbatim}
\end{frame}

\begin{frame}
  \frametitle{CI on the Mean of a Normal Variable} 
  The two-sided $CI_{(1-\alpha)}$ for the mean of a normal population
  with known variance $\sigma^2$ is given by:
  \begin{equation*}
    \bar{x} - \frac{\sigma}{\sqrt{N}}Z_{(\alpha/2)} \leq \mu \leq \bar{x} + \frac{\sigma}{\sqrt{N}}Z_{(\alpha/2)}
  \end{equation*}
  where $(1-\alpha)$ is the confidence level and $z_{(\alpha/2)}$ is
  the $(1-\alpha/2)$-quantile of the standard normal distribution.

  For the more usual case with an unknown variance,
  \begin{equation*}
    \bar{x} - \frac{s}{\sqrt{N}}t_{(\alpha/2;N-1)} \leq \mu \leq \bar{x} + \frac{s}{\sqrt{N}}t_{(\alpha/2;N-1)} 
  \end{equation*}
  where $t_{(\alpha/2;N-1)}$ is the corresponding quantile of the $t$
  distribution with $N-1$ degrees of freedom.
\end{frame}

\begin{frame}
  \frametitle{CI on the Variance of a Normal Variable} 
  In the same way, a two-sided confidence interval on the variance of
  a normal variable can be easily calculated:
  \begin{equation*}
    \frac{(N-1)s^2}{\chi^2_{\alpha/2;N-1}} \leq \sigma^2 \leq \frac{(N-1)s^2}{\chi^2_{1-\alpha/2;N-1}}
  \end{equation*}
  where $\chi^2_{\alpha/2;N-1}$ and $\chi^2_{1-\alpha/2;N-1}$ are the
  upper and lower $(\alpha/2)$-quantiles of the $\chi^2$ distribution
  with $N-1$ degrees of freedom.
\end{frame}

\begin{frame}[singleslide,fragile]
  \frametitle{Calculating the CI with R} 

  Remember that we don't want to do all these calculations by hand! It
  is important to understand what they mean, but in practice you will
  do something like this:
  
{\small
\begin{verbatim}
> population <- rnorm(5000) # our hypotethical population
> sample.size = 20
> x1 <- sample(population,sample.size) # replace with experiment

> mean.estimator <- mean(x1)
> sd.estimator <- sd(x1)

> left <- mean.estimator - (sd.estimator/sqrt(sample.size))*qt(0.95,df=sample.size-1)
> right <- mean.estimator + (sd.estimator/sqrt(sample.size))*qt(0.95,df=sample.size-1)

> c(left,right)
[1] -0.5218866  0.3356534
\end{verbatim}}
%TODO: Add another R example with real data
\end{frame}

\begin{frame}[singleslide,fragile]
  \frametitle{What if we want a smaller Interval?} 

  One way to decrease the size of the confidence interval, without
  losing confidence, is increasing the size of a sample. This has its
  own problems which we will see in the future (e.g. cost of
  sampling).
  
{\small
\begin{verbatim}
> population <- rnorm(5000) # our hypotethical population
> sample.size = 100 # INCREASED SAMPLE SIZE
> x1 <- sample(population,sample.size) # replace with experiment

> mean.estimator <- mean(x1)
> sd.estimator <- sd(x1)

> left <- mean.estimator - (sd.estimator/sqrt(sample.size))*qt(0.95,df=sample.size-1)
> right <- mean.estimator + (sd.estimator/sqrt(sample.size))*qt(0.95,df=sample.size-1)

> c(left,right)
[1] -0.1163320  0.2011607 # DECREASED CONFIDENCE INTERVAL
\end{verbatim}}
%TODO: Add another R example with real data
\end{frame}

\begin{frame}
  \frametitle{Tolerance Intervals} 

  ``A tolerance interval is a {\bf enclosure} interval for a specified
  proportion of the samplede population, not its mean or standard
  deviation. For a specified confidence level, you may want to
  determine lower and upper bounds such that a given percent of the
  population is contained within them.''

  \hfill{\tiny J.G. Ramirez:
    \url{https://www.sas.com/resources/whitepaper/wp_4430.pdf}}

  \begin{center}
    90\% enclosure of a N(50,2) population
    \includegraphics[width=0.8\textwidth]{img/enclosure}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Tolerance Intervals} 
  The common practice in engineering of defining specification limits
  by adding $\pm 3\sigma$ to a given estimate of the mean arises from
  this definition - for a normally-distributed population,
  approximately 99.75\% of the observations will fall within these
  limits.
  
  However, in most cases the true variance is unknown. So we have to
  use its estimate, $s^2$, and compensate for the uncertainty in this
  estimation. The two-sided tolerance interval is given as: 
  \begin{equation*}
    \bar{x} \pm \sqrt{(N-1)(N+z^2_{(\alpha/2)}}{N_{\chi^2_{(\gamma;N-1)}}}
  \end{equation*}
  In which $\gamma$ is the proportion of the population to be
  enclosed, and $1-\alpha$ is the desired confidence level for the
  interval.
\end{frame}

\begin{frame}[singleslide,fragile]
  \frametitle{Another Example} 
  We are bulding a program that should finish its operation in between
  10 and 30$\mu s$. An initial analysis would be to run the programs a
  few times to calculate the tolerance interval for its running time.

{\smaller
\begin{verbatim}
> runtime <- c(14.92869, 13.65345, 14.63093, 14.38412, 
               14.98059, 13.92460, 14.81254, 14.26117
               13.31676, 19.80000)
> df <- length(runtime)
> prop <- 0.9
> conf <- 0.95
> spread <- sqrt(((df-1)*(df+qnorm(conf/2)^2))/(df*qchisq(prop,df=df-1)))
> left <- mean(runtime) - spread
> right <- mean(runtime) + spread
> c(left,right)
[1] 14.08623 15.64972
\end{verbatim}}
% TODO: check that this calculation of tolerance interval is correct
\end{frame}

\begin{frame}
  \frametitle{Prediction Intervals} 
  Prediction intervals quantify the uncertainty associated with
  forecasting the value of a future observation;
  
  \medskip

  Essentially, one is intersted in obtaining an interval within which
  he or she can declare that the next observation will fall with a
  given probability;

  \medskip

  For a normal distribution, we have:
  \begin{equation*}
    \bar{x} - t_{(\alpha/2;N-1)}s/sqrt{1+\frac{1}{N}} \leq X_{N+1} \leq \bar{x} + t_{(\alpha/2;N-1)}s/sqrt{1+\frac{1}{N}}
  \end{equation*}
  which is similar to the confidence interval for the mean, but adding
  1 to the term within the square root to account for the prediction
  noise.
\end{frame}

\begin{frame}
  \frametitle{Wrapping up} 
  Statistical intervals quantify the uncertainty associated with
  different aspects of estimation;

  \bigskip

  Reporting intervals is always better than point estimates, as it
  provides to you (and your readers) the necessary information to
  quantify the location and spread of your estimated values;

  \bigskip

  The correct interpretation is a little tricky, but it is essential
  in order to derive the correct conclusions based on the statistical
  interval of interest.

  \bigskip

  \rule{\textwidth}{0.4pt}
  {\smaller
    Related reading:
    \begin{itemize}
      \item J.G. Ramirez, Statistical Intervals: Confidence, Prediction, Enclosure:\\
        \url{https://www.sas.com/resources/whitepaper/wp_4430.pdf}
      \item D.C. Montgomery and G.C. Runger, ``Applied Statistics and
        Probability for Engineers'', chapter 8, 3rd Ed., Wiley 2005.
    \end{itemize}    
  }

\end{frame}

\begin{frame}
  \frametitle{}
  \begin{center}
    Did you understand everything?\\
    Another mini-break!
  \end{center}
\end{frame}


%TODO: this should probably be a separate chapter: 
%TODO: Statistical inference (value comparison) and simple comparisons (pop comp) 
\section{Statistical Inference}
\subsection{Introduction}
\begin{frame}
  \frametitle{Introduction to Statistical Inference} 

  Point Estimators and Statistical Intervals belong to a branch of
  statistics known as \emph{descriptive statistics}. That is, these
  methods are focused on accurately describing characteristics such as
  the location and uncertainty about a given population parameter;

  \vfill

  While these concepts are certainly important, in many cases
  description is not enough -- someone may need the decision-making
  tools to deal with information from random samples, tools that allow
  a research to perform \structure{inference} with a quantifiable
  degree of certainty.
\end{frame}

\begin{frame}
  \frametitle{Statistical Hypotheses}
  {\small
  A \structure{hypothesis} is a proposed explanation for an observable phenomenon.
  
  Scientific hypotheses must satisfy (at least) two conditions:
  \begin{itemize}
  \item Testability;
  \item Falsifiability;
  \end{itemize}

  \bigskip

  The \structure{hypothetico-deductive} model of construction of
  scientific knowledge includes:
  \begin{itemize}
  \item Formulation of a falsifiable hypotheses;
  \item Refutation or corroboration of the hypotheses by the data;
  \item Comparison between alternative hypotheses -- principle of
    parsimony (Ockham's razor);
  \item Predictive power;
  \end{itemize}}

  % TODO: maybe add quotes from popper/ockham?
\end{frame}

\subsection{Hypotheses}
\begin{frame}
  \frametitle{Definitions of Statistical Hypotheses} 
  Statistical hypotheses are defined as objective statements about
  parameters of one or more populations;

  \bigskip

  \alert{Attention:} the statements in statistical hypotheses are
  about parameters of the population or model, {\bf not the sample.}

  \bigskip

  On frequentist approaches, the formal test of hypotheses involves
  the contrast between null and alternate hypotheses.

  \begin{columns}
    \column{.5\textwidth}
    \begin{block}{Null hypothesis ($H_0$)}
      \begin{itemize}
        \item Absence of effects;
        \item Conservative model;
        \item Point value for the parameter.
      \end{itemize}
      {\bf Example:} $H_0 : \mu = 25$
    \end{block}
    \column{.5\textwidth}
    \begin{block}{Null hypothesis ($H_A$)}
      \begin{itemize}
        \item Presence of some effect;
        \item Existence of something ``new'';
        \item Interval value for the parameter.
      \end{itemize}
      {\bf Example:} $H_A : \mu \neq 25$
    \end{block}
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{Statistical Hypotheses: Working them out}
  Determination of the reference value for the null hypothesis $H_0$:
  \begin{itemize}
  \item Previous knowledge about the process (investigation of changes);
  \item Value obtained from theory or models (model validation);
  \item Project requirements (investigation of system compliance);
  \end{itemize}

  \bigskip

  Hypothesis testing involves:
  \begin{itemize}
  \item Obtaining the sample;
  \item Calculation of test statistics;
  \item Decision based on the computed value;
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Statistical Hypothesis: an example}
  {\small
    \begin{columns}
      \column{0.2\textwidth}
      \includegraphics[width=1\textwidth]{img/peas}
      \column{0.8\textwidth} Suppose you are a large-scale consumer of
      green peas, and you want to determine if the 500g packages from
      a supplier really contain their nominal wight (at least on
      average).
    \end{columns}
  }
  
  \bigskip
  
  In this case, the null hypothesis could be defined as: \emph{the
    average net weight of a package is 500g}, and the alternative of
  interest could be expressed as the complementary inequality.
  \begin{equation*}
    \begin{cases}
      H_0 : \mu = 500g\\
      H_1 : \mu \neq 500g
    \end{cases}
  \end{equation*}
  Suppose still that you get 10 randomly selected packs from the supplier
  (in other words, $N=10$), and you then measure their contents using
  a calibrated scale;
\end{frame}

\begin{frame}
  \frametitle{Statistical Hypothesis: an example} 
  Since the sample mean $\bar{x}$ is a good estimator of the real mean
  $\mu$, we can assume:
  
  \medskip

  \begin{itemize}
  \item If $\bar{x} \cong 500g$ - then $H_0$ is corroborated;
  \item If $\bar{x} \ll 500g$ or $\bar{x} \gg 500g$ - $H_0$ is refuted;
  \end{itemize}
  
  \medskip

  This suggests that we use the value of $\bar{x}$ as the basis for a
  statistical test.
  
  \vfill

  First, we need to define a \structure{critical region} for the rejection of $H_0$.
  \begin{center}
    \includegraphics[width=0.9\textwidth]{img/criticalregion}
  \end{center}
  \hfill The big question: how do we define \structure{$\Delta$}?
\end{frame}

\subsection{Inferential Errors}
\begin{frame}
  \frametitle{Type I error}
  \begin{block}{}
    {\bf Type I error} (AKA false positive): rejecting the null
    hypothesis when it is true.
  \end{block}
  
  \vspace{1cm}

  The probability of occurrence of a false positive in any hypothesis
  testing procedure is generally known as the \structure{significance
    level} of the test. It is generally represented by the Greek
  letter $\alpha$:

  \begin{equation*}
    \alpha = P(\text{type I error}) = P(\text{reject } H_0|H_0 \text{ is true})
  \end{equation*}

  Another frequently used term is the \structure{confidence level} of
  the test, given by $(1-\alpha)$
\end{frame}

\begin{frame}
  \frametitle{Type I error} 

  \begin{block}{}
  For a given sample, the selected value of $\alpha$ defines the
  critical threshold for the rejection of $H_0$. Bigger $\alpha$ --
  lower treshold -- higher probability of a type I error.
  \end{block}

  \bigskip

  If $H_0$ is true (i.e., if $\mu = 500g$), the distribution of values
  of $\bar{x}$ is approximately normal (remember the CLT), with
  average 500 and variance given by $s^2/n$.

  \bigskip

  For a Type-I error probability $\alpha = 0.05$, the critical values
  of the distribution of $\bar{x}$ are those for which the probability
  density within the acceptance region is $1-\alpha = 0.95$.

  \bigskip
  
  \hfill \includegraphics[width=0.4\textwidth]{img/alpha}
\end{frame}

\begin{frame}
  \frametitle{Type II error}
  \begin{block}{}
    {\bf Type II error} (AKA. false negative): failure to reject the
    null hypothesis when it is false.
  \end{block}

  \bigskip

  The probability of occurrence of a false negative in any hypothesis
  testing procedure is generally represented by $\beta$:
  \begin{equation*}
    \beta = P(\text{type II error}) = P(\text{not reject } H_0|H_0 \text{ is false})
  \end{equation*}

  \bigskip

  The quantity $(1-\beta)$ is known as the \structure{power of the
    test}, and quantifies its sensitivity to effects that violate the
  null hypothesis.

  \vspace{1cm}

  \begin{exampleblock}{In other words}
    A type II error usually happen when the difference between the
    effect and the null hypothesis is too small to be detected. In
    this case, the testing procedure is not sensitive enough.
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Type II error}

  \begin{columns}
    \column{.5\textwidth}

    Unlike the Type-I error, the definiton of the Type-II error rate
    requires further specification of the value of the parameter being
    investigated;

    \bigskip

    The probability of failing to reject a false $H_0$ is strongly
    dependent on the magnitude of the difference between the value
    under $H_0$ and the real value of the parameter.

    \column{.5\textwidth}
    \includegraphics[width=1\textwidth]{img/beta-a}\\
    \includegraphics[width=1\textwidth]{img/beta-d}    
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{Type II error}
  
  The power of a test is governed by several factors:
  \begin{itemize}
    \item \structure{Controllable factors}: significance level $\alpha$, sample size $N$;
    \item \structure{Uncontrollable factors}: real value of the parameter in the population;
  \end{itemize}
  If $H_0$ is false, the smaller the magnitude of the difference
  between the real value of the parameter and the one under the null
  hypothesis, the greater the probability of a type II error.

  \vspace{1.5cm}

  \begin{alertblock}{However!}
    If the difference between $H_0$ and the parameter is too small,
    the practical importance of the effect (and the importance of the
    type II error) also gets insignificant.
  \end{alertblock}
\end{frame}

\begin{frame}
  \frametitle{Considerations about type I, II errors} 

  {\bf Type I error} ($\alpha$) depends only on the distribution of
  the null hypothesis -- easier to control;
  
  \smallskip

  {\bf Type II error} ($\beta$) depends on the real value of the
  parmeter -- more difficult to specity and control;

  \bigskip

  These characteristics lead to the following classification of the
  conclusions obtained from hypothesis testing:
  \begin{block}{}
    \begin{itemize}
    \item Rejection of $H_0$ -- strong conclusion;
    \item Failure to reject $H_0$ -- weak conclusion (but can be strengthened);
    \end{itemize}
  \end{block}

  It is important to remember that failing to reject $H_0$ does not
  mean that there is evidence in favor of $H_0$ -- it inly suggests
  that it is a better model than the alternative.

\end{frame}

\begin{frame}
  \frametitle{Easy way to remember type I, II errors}
  \begin{center}
    \includegraphics[width=.8\textwidth]{img/type_I_type_II_errors}\\
    Also -- mini break!
  \end{center}
\end{frame}



\subsection{Hypothesis testing procedure}
\begin{frame}
  \frametitle{General Procedure for Hypothesis testing}
  \begin{columns}
    \column{.7\textwidth}
    \begin{itemize}
    \item Identify the parameter of interest;
    \item Define $H_0$ and $H_A$ (one or two sided)
    \item Determined desired $\alpha$, $\beta$;
    \item Define minimally interesting effect $\delta^*$;
    \item Calculate sample size;
    \item Determine the test statistic and critical region;
    \item Compute the statistic;
    \item Decide whether or not to reject $H_0$;
    \end{itemize}
    \column{.3\textwidth}
    \includegraphics[width=.6\textwidth]{img/hypothesis-wine}
  \end{columns}
  \rule{1\textwidth}{0.4pt}
  {\tiny Image (c) Roots Run Deep Winery: \url{http://www.rootsrundeep.com/hypothesis.html}}
\end{frame}

\begin{frame}
  \frametitle{Hypothesis testing: Mean of a normal dist, variance known}
  \begin{columns}
    \column{0.2\textwidth}
    \includegraphics[width=1\textwidth]{img/peas}
    \column{0.8\textwidth} Back to the green peas example, we want to
    determine if there is any significant deviation on the mean weight
    of the packages. Assume for now that the variance of the process
    is known. The test hypothesis are defined as:
  \end{columns}
  
  \bigskip

  \begin{equation*}
    \begin{cases}
      H_0 : \mu = 500g\\
      H_1 : \mu \neq 500g
    \end{cases}
  \end{equation*}
  Let the desired significance level be $\alpha = 0.05$;

  \bigskip

  Given these characteristics, we expect that the sampling
  distribution of $\bar{X}$ is also normal, with variance
  Var($\bar{X}$) $= \sigma^2/n$. If $H_0$ is true, the mean of the
  population is $\mu_{\bar{X}} = \mu_0 = 500$;
\end{frame}

\begin{frame}
  \frametitle{Hypothesis testing: Mean of a normal dist, variance known}
  Based on these characteristics, the variable
  \begin{equation*}
    Z_0 = \frac{\bar{X} - \mu_0}{\sigma/\sqrt{n}}
  \end{equation*}
  will be distributed according to the standard normal, N(0,1), but
  {\bf only if $H_0$ is true}.

  \bigskip

  This result implies a probablility of $(1-\alpha)$ that $Z_0$ will
  fall within the range $(\pm z_{\sigma/2})^b$ if $H_0$ is true. This
  provides a selection criterion between $H_0$ and $H_1$:
  \begin{itemize}
    \item If $|z_0| > z_{alpha/2}$, we reject $H_0$ at the confidence
      level $1-\alpha$;
    \item Otherwise, there is not enough evidence to reject $H_0$
  \end{itemize}  
\end{frame}

\begin{frame}
  \frametitle{Hypothesis testing: Mean of a normal dist, variance known}

  Assume that we got $\bar{x} = 496.48$ from our $n=10$ observations,
  and that $\sigma = 10g$. In this case.

  \medskip

  \begin{equation*}
    z_0 = \frac{496.48 - 500}{10/\sqrt{10}} = -1.113
  \end{equation*}

  \medskip

  The critical values of the standard normal distribution are taken from its 
  quantiles, so $\pm z_{\sigma/2} = \pm z_{0.025} = \pm 1.96$;
  
  Since $|z0| < Z_{0.025}$, we can conclude that there is not enough
  evidence to reject $H_0$ at the 95\% confidence level.
\end{frame}

\begin{frame}[singleslide,fragile]
  \frametitle{Hypothesis testing: Mean of a normal dist, variance known}
{\small
\begin{verbatim}
> install.packages("TeachingDemos")
> library(TeachingDemos)

> peas <- scan("Rfiles/greenpeas.txt")
> z.test (as.numeric(peas), mu=500, stdev=10)

One Sample z-test
data: as.numeric(peas)
z = -1.1131, n = 10.0000, Std. Dev. = 10.0000, 
Std. Dev. of the sample mean = 3.1623, 
p-value = 0.2657
alternative hypothesis: true mean is not equal to 500
95 percent confidence interval:
 490.282 502.678
sample estimates:
mean of as.numeric(peas) 
                  496.48
\end{verbatim}}
\end{frame}

\subsection{Another Example}
\begin{frame}
  \frametitle{Hypothesis testing 2: normal dist, variance unknown}
  Suppose now a more realistic situation: we don't know the real
  variance of the population. Besides, assume that we are interested
  in detecting only negative deviations (We only care if the real
  number of peas is less than the stated amount).
  
  \bigskip
  
  The test hypotheses can be defined as: 
  \begin{equation*}
    \begin{cases}
      H_0 : \mu = 500g\\
      H_1 : \mu < 500g
    \end{cases}
  \end{equation*}

  \bigskip

  In this second scenario, we want to be more conservative, so we pick
  a significance level of $\alpha = 0.01$;
  
  \bigskip

  It can be shown that, {\bf if $H_0$ is true} then
  %TODO: Explain what is T0 and tn-1: percentiles of t distribution?
  \begin{equation*}
    T_0 = \frac{\bar{X} - \mu_0}{S/\sqrt{n}}\sim t_{n-1}
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{Hypothesis testing 2: normal dist, variance unknown}
  From the same data as in the previous example, we can calculate that 
  $\bar{x} = 496.48g$, $n = 10$, $s=6.97g$. From this we find out that:

  \bigskip

  \begin{equation*}
    t_0 = \frac{496.48 - 500}{6.79/\sqrt{10}} = -1.5969
  \end{equation*}

  \bigskip

  The critical value of this test statistic for the desired
  significance is $t_{\alpha,n-1} = t_{0.01,9} = -2.82$;

  \bigskip

  Given that $t_0 > -2.54$, we conclude that the evidence is
  insufficient to reject $H_0$ at the 99\% confidence level;
  
  \begin{block}{In the end}
    From analyzing this sample of 10 peas packages, we do not have
    enough evidence to affirm, with a 99\% confidence level, that the
    mean weight of pea packages is less than 500g. 
  \end{block}

\end{frame}

\begin{frame}[singleframe,fragile]
  \frametitle{Hypothesis Testing 2: calculating it with R}
  {\small
\begin{verbatim}
> library(TeachingDemos)
> peas <- scan("Rfiles/greenpeas.txt")
> t.test(peas,alternative="less",mu=500,conf.level=0.99)

        One Sample t-test

data:  peas
t = -1.5969, df = 9, p-value = 0.07237
alternative hypothesis: true mean is less than 500
99 percent confidence interval:
     -Inf 502.6991
sample estimates:
mean of x 
   496.48
\end{verbatim}
  }
%TODO: include ``by hand'' calculation of critical region in R
\end{frame}

\subsection{Analysing Results}
\begin{frame}
  \frametitle{Hypothesis testing: description of results}
  \begin{block}{}
    (In)Sufficient evidence for rejecting $H_0$ at the significance
    level $\alpha$
  \end{block}

  \bigskip

  Even though this is correct (and better than just comparing single
  values), this description is still relatively poor:

  \medskip

  \begin{enumerate}
  \item It does not provide information on the intensity of the
    evidence for rejection/non rejection;
  \item It imposes a predetermined significance level to the consumer
    of the information;
  \item It does not provide information about the magnitude of the
    effect that was found, or the sensitivity of the test;
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Hypothesis testing: p-values}
  \begin{block}{The p-value:}
    The lowest significance level that would lead to the rejection of
    $H_0$ for the available data.
  \end{block}
  
  \bigskip
  
  Can be interpreted as the probability that, if $H_0$ is true, that
  the test statistic would obtain a value at least as extreme as the
  one obtained.

  \bigskip

  For our previous example, the p-value could have been calculated as:
  \begin{equation*}
    p = P(t_0 \leq -1.597|H_0 = \text{TRUE} =
    \int^{-1.597}_{-\inf}(t_9)dt = 0.07237
  \end{equation*}

  \bigskip
  
  \begin{block}{}
    It is still important to define the significance level a priori!
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Beware the Caveats of hypothesis testing!}

  The p-value is a very powerful tool for analysing the result of a
  hypothesis test procedure. However, even the p-value can lead
  to erroneous conclusions if not analyzed carefully:

  \bigskip

  \begin{block}{Some simple caveats}
    \begin{itemize}
    \item Multiplicative effects of multiple experiments;
    \item Huge n sizes leading to high confidence for small effects;
    \item Type II errors
    \item Throwing away low confidence results
    \end{itemize}
  \end{block}

  \bigskip

  But you must be tired by now, so we will talk about these guys next
  class!
\end{frame}


\section{End Notes}

\subsection{Summary}
\begin{frame}
  \frametitle{Today you learned}
  \begin{itemize}
  \item Statistical population as a proxy for the unknown truth we
    want to understand through experiments;
  \item That there are different methods to infer information about
    the population from the experiments (samples);
  \item That different statistical methods have different accuracies
    and confidence levels, and these can be calculated;
  \item About hypothesis testing as a way to make decisions about a
    population based on a sample;
  \item About how to calculate and analyse a hypothesis about a
    parameter of the population;
  \end{itemize}
\end{frame}

\subsection{Homework 2}
\begin{frame}
  \frametitle{Homework 2}
  {\smaller
  \begin{block}{Basic Data analysis}
    \begin{itemize}
    \item Load two data files related to your research into R data
      frames (experiment results, data sets, etc);
    \item Find out, for each data set: variables, their means,
      variances, maximum and minimum values;
    \item Plot relevant plots to characterize these data sets;
    \item Compare these data sets using statistical estimators (point
      estimators, interval estimators, etc)
    \item Describe your findings;
    \end{itemize}
  \end{block}
  \begin{block}{Submission materials}
    \begin{itemize}
    \item \structure{Files 1..n:} text files containing the data used;
    \item \structure{File n+1:} R file (text file) containing the
      tasks above; R file must contain comments explaining what each
      command block does.
    \end{itemize}
  \end{block}}
  \rule{\textwidth}{0.4pt} {\tiny If you don't have useable data
    related to your research, you can use the ``air quality'' data set
    in the ``datasets'' R package}
\end{frame}

\section{Final Notes}
\subsection{Image Information}
\begin{frame}
  \frametitle{Credits}
  {\smaller
  \begin{itemize}
    %TODO: Generate self image for pool of balls
  \item Pool of balls image: \url{http://goo.gl/y8doaN}
    %TODO: Generate self image for green ball
  \item Green ball: \url{http://goo.gl/Fb8z68}
    %TODO: Generate self image for MVUE (min-max/2 vs regular mean)
  \item MVUE image: D.C.Montgomery, G.C. Runger, ``Applied Statistics and Probability for Engineers'', Wiley 2003
  \item Peas image: \url{http://www.storko.eu/ed_files/image/green-peas.jpg}
  \end{itemize}
  \medskip
  \begin{block}{This lecture notes is a derived work of}
    Felipe Campelo (2015), ``Lecture Notes on Design and Analysis of Experiments''\\
    Online: \url{https://github.com/fcampelo/Design-and-Analysis-of-Experiments}
    Creative Commons BY-NC-SA 4.0.
  \end{block}}
\end{frame}

\end{document}
